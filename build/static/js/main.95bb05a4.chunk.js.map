{"version":3,"sources":["utilities.js","App.js","index.js"],"names":["drawRect","detections","ctx","forEach","prediction","x","y","width","height","text","strokeStyle","font","fillStyle","beginPath","fillText","rect","stroke","App","webcamRef","useRef","canvasRef","runCoco","a","cocossd","net","setInterval","detect","current","video","readyState","videoWidth","videoHeight","obj","console","log","getContext","useEffect","className","ref","muted","style","position","marginLeft","marginRight","left","right","textAlign","zindex","ReactDOM","render","StrictMode","document","getElementById"],"mappings":"+ZAEaA,EAAW,SAACC,EAAYC,GACjCD,EAAWE,SAAQ,SAAAC,GAAe,IAAD,cACCA,EAAU,KADX,GACtBC,EADsB,KACnBC,EADmB,KAChBC,EADgB,KACTC,EADS,KAEvBC,EAAOL,EAAU,MAGvBF,EAAIQ,YADU,QAEdR,EAAIS,KAAO,aACXT,EAAIU,UAHU,QAIdV,EAAIW,YACJX,EAAIY,SAASL,EAAMJ,EAAGC,GACtBJ,EAAIa,KAAKV,EAAGC,EAAGC,EAAOC,GACtBN,EAAIc,aC2FGC,MA3Ff,WACE,IAAMC,EAAYC,iBAAO,MACnBC,EAAYD,iBAAO,MAGnBE,EAAO,uCAAG,4BAAAC,EAAA,sEAGIC,MAHJ,OAGRC,EAHQ,OAMdC,aAAY,WACVC,EAAOF,KACN,IARW,2CAAH,qDAWPE,EAAM,uCAAG,WAAOF,GAAP,uBAAAF,EAAA,yDAGkB,qBAAtBJ,EAAUS,SACK,OAAtBT,EAAUS,SAC6B,IAAvCT,EAAUS,QAAQC,MAAMC,WALb,wBAQLD,EAAQV,EAAUS,QAAQC,MAC1BE,EAAaZ,EAAUS,QAAQC,MAAME,WACrCC,EAAcb,EAAUS,QAAQC,MAAMG,YAG5Cb,EAAUS,QAAQC,MAAMrB,MAAQuB,EAChCZ,EAAUS,QAAQC,MAAMpB,OAASuB,EAGjCX,EAAUO,QAAQpB,MAAQuB,EAC1BV,EAAUO,QAAQnB,OAASuB,EAlBhB,UAsBOP,EAAIE,OAAOE,GAtBlB,QAsBLI,EAtBK,OAuBXC,QAAQC,IAAIF,GAGN9B,EAAMkB,EAAUO,QAAQQ,WAAW,MAIzCnC,EAASgC,EAAK9B,GA9BH,4CAAH,sDAqCZ,OAFAkC,qBAAU,WAAKf,MAAW,IAGxB,yBAAKgB,UAAU,OACb,4BAAQA,UAAU,cAChB,kBAAC,IAAD,CACEC,IAAKpB,EACLqB,OAAO,EACPC,MAAO,CACLC,SAAU,WACVC,WAAY,OACZC,YAAa,OACbC,KAAM,EACNC,MAAO,EACPC,UAAW,SACXC,OAAQ,EACRxC,MAAO,IACPC,OAAQ,OAIZ,4BACE8B,IAAKlB,EACLoB,MAAO,CACLC,SAAU,WACVC,WAAY,OACZC,YAAa,OACbC,KAAM,EACNC,MAAO,EACPC,UAAW,SACXC,OAAQ,EACRxC,MAAO,IACPC,OAAQ,UC5FpBwC,IAASC,OACP,kBAAC,IAAMC,WAAP,KACE,kBAAC,EAAD,OAEFC,SAASC,eAAe,W","file":"static/js/main.95bb05a4.chunk.js","sourcesContent":["// import { fill } from \"@tensorflow/tfjs\";\r\n\r\nexport const drawRect = (detections, ctx) => {\r\n    detections.forEach(prediction => {\r\n        const [x, y, width, height] = prediction['bbox'];\r\n        const text = prediction['class'];\r\n    \r\n        const color = 'white';\r\n        ctx.strokeStyle = color;\r\n        ctx.font = '18px Arial';\r\n        ctx.fillStyle = color;\r\n        ctx.beginPath();\r\n        ctx.fillText(text, x, y);\r\n        ctx.rect(x, y, width, height);\r\n        ctx.stroke();\r\n    \r\n    })\r\n}","// Import dependencies\n// eslint-disable-next-line\nimport React, { useRef, useState, useEffect } from \"react\";\n// eslint-disable-next-line\nimport * as tf from \"@tensorflow/tfjs\";\n// 1. TODO - Import required model here\n// e.g. import * as tfmodel from \"@tensorflow-models/tfmodel\";\nimport * as cocossd from \"@tensorflow-models/coco-ssd\";\nimport Webcam from \"react-webcam\";\nimport \"./App.css\";\n// 2. TODO - Import drawing utility here\n// e.g. import { drawRect } from \"./utilities\";\nimport { drawRect } from \"./utilities\";\n\nfunction App() {\n  const webcamRef = useRef(null);\n  const canvasRef = useRef(null);\n\n  // Main function\n  const runCoco = async () => {\n    // 3. TODO - Load network \n    // e.g. const net = await cocossd.load();\n    const net = await cocossd.load();\n    \n    //  Loop and detect hands\n    setInterval(() => {\n      detect(net);\n    }, 10);\n  };\n\n  const detect = async (net) => {\n    // Check data is available\n    if (\n      typeof webcamRef.current !== \"undefined\" &&\n      webcamRef.current !== null &&\n      webcamRef.current.video.readyState === 4\n    ) {\n      // Get Video Properties\n      const video = webcamRef.current.video;\n      const videoWidth = webcamRef.current.video.videoWidth;\n      const videoHeight = webcamRef.current.video.videoHeight;\n\n      // Set video width\n      webcamRef.current.video.width = videoWidth;\n      webcamRef.current.video.height = videoHeight;\n\n      // Set canvas height and width\n      canvasRef.current.width = videoWidth;\n      canvasRef.current.height = videoHeight;\n\n      // 4. TODO - Make Detections\n      // e.g. const obj = await net.detect(video);\n      const obj = await net.detect(video);\n      console.log(obj)\n\n      // Draw mesh\n      const ctx = canvasRef.current.getContext(\"2d\");\n\n      // 5. TODO - Update drawing utility\n      // drawSomething(obj, ctx)  \n      drawRect(obj, ctx);\n    }\n  };\n\n  // eslint-disable-next-line\n  useEffect(()=>{runCoco()},[]);\n\n  return (\n    <div className=\"App\">\n      <header className=\"App-header\">\n        <Webcam\n          ref={webcamRef}\n          muted={true} \n          style={{\n            position: \"absolute\",\n            marginLeft: \"auto\",\n            marginRight: \"auto\",\n            left: 0,\n            right: 0,\n            textAlign: \"center\",\n            zindex: 9,\n            width: 640,\n            height: 480,\n          }}\n        />\n\n        <canvas\n          ref={canvasRef}\n          style={{\n            position: \"absolute\",\n            marginLeft: \"auto\",\n            marginRight: \"auto\",\n            left: 0,\n            right: 0,\n            textAlign: \"center\",\n            zindex: 8,\n            width: 640,\n            height: 480,\n          }}\n        />\n      </header>\n    </div>\n  );\n}\n\nexport default App;\n","import React from 'react';\nimport ReactDOM from 'react-dom';\nimport './index.css';\nimport App from './App';\n\nReactDOM.render(\n  <React.StrictMode>\n    <App />\n  </React.StrictMode>,\n  document.getElementById('root')\n);"],"sourceRoot":""}